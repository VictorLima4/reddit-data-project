{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pymysql\n",
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import praw\n",
    "import mysql.connector\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the variables from .env file for privicy\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets the actual values fro, .env\n",
    "id = os.getenv(\"client_id\")\n",
    "secret = os.getenv(\"client_secret\")\n",
    "pw = os.getenv(\"pw\")\n",
    "user = \"Scraper 1.0 by /u/ZaaLiah\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connection to the API\n",
    "reddit = praw.Reddit(client_id=id, client_secret=secret, user_agent=user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search fro the trending hot posts on r/ Politics and store those in a df\n",
    "df = []\n",
    "for submission in reddit.subreddit('politics').hot(limit=1000):\n",
    "    df.append([submission.id, submission.created_utc, submission.title, submission.num_comments, submission.score])\n",
    "df = pd.DataFrame(df, columns = ['id', 'timestamp', 'title', 'num_comments', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts timestamp column into only Date column and drops the old timestamp column\n",
    "df['date'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
    "df = df.drop('timestamp', axis=1)\n",
    "df = df[['id', 'date', 'title', 'num_comments', 'score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connects to my SQL Severs, creates a cursor and writes new posts on the DB\n",
    "#Creates my fact table 'f_reddit_posts'\n",
    "#If the post already exists in my DB it will update the row instead of creating a duplicate\n",
    "mydb = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"root\",\n",
    "    password = pw,\n",
    "    database=\"localdb\",\n",
    "    port='3306'\n",
    "  )\n",
    "\n",
    "cursor = mydb.cursor()\n",
    "for row in df.itertuples():\n",
    "  cursor.execute(\n",
    "    'INSERT INTO f_reddit_posts (id, date, title, num_comments, score)VALUES (%s,%s,%s,%s,%s) ON DUPLICATE KEY UPDATE id=VALUES (id)',\n",
    "    (row.id,row.date,row.title,row.num_comments,row.score),\n",
    "  row)\n",
    "mydb.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads the 'f_reddit_posts' table and stores it on a df\n",
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM f_reddit_posts\n",
    "\"\"\"\n",
    "mydb = mysql.connector.connect(\n",
    "    host = \"localhost\",\n",
    "    user = \"root\",\n",
    "    password = pw,\n",
    "    database=\"localdb\",\n",
    "    port='3306'\n",
    "  )\n",
    "df = pd.read_sql(sql, mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs the sentiment analysis on the posts\n",
    "sia = SIA()\n",
    "df['compound'] = [sia.polarity_scores(x)['compound'] for x in df['title']]\n",
    "df['neg'] = [sia.polarity_scores(x)['neg'] for x in df['title']]\n",
    "df['neu'] = [sia.polarity_scores(x)['neu'] for x in df['title']]\n",
    "df['pos'] = [sia.polarity_scores(x)['pos'] for x in df['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the columns with the sentiment analysis results\n",
    "df['label'] = 0\n",
    "df.loc[df['compound'] > 0.2, 'label'] = 1\n",
    "df.loc[df['compound'] < -0.2, 'label'] = -1\n",
    "df = df[['id', 'compound', 'neg', 'neu', 'pos', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connects to my SQL Severs, creates a cursor and writes the results on the DB\n",
    "#Creates my dimension table 'd_rp_sentiment'\n",
    "cursor = mydb.cursor()\n",
    "for row in df.itertuples():\n",
    "  cursor.execute(\n",
    "    'INSERT INTO d_rp_sentiment (id, compound, neg, neu, pos, label)VALUES (%s, %s, %s, %s, %s, %s) ON DUPLICATE KEY UPDATE id=VALUES (id)',\n",
    "    (row.id,row.compound,row.neg,row.neu,row.pos,row.label),\n",
    "  row)\n",
    "mydb.commit()\n",
    "cursor.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
